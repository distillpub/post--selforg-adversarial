<d-article>
<h1>Demo&#x2F;Video</h1>
<p>We show the adversarial MNIST demo. One problem here is that looking at the demo before reading anything will result in not knowing what to do there.</p>
<p>One option is to have a video explaining what is going on here, before showing the demo. Alternatively, here we have just a video, and the demo is presented at the end of the adversarial MNIST CA section.</p>
<h1>Introduction</h1>
<p>&lt;Recap of what happened on MNIST CA and introduce the new adversarial task + biological justification&gt;</p>

<p>The Growing Neural Cellular Automata [cite] and Self-classifying MNIST Digits [cite] articles in this thread presented the Neural Cellular Automata (Neural CAs) model and showed how these models can be trained end-to-end differentiably to accomplish self-organising task such as pattern growth and digit self-classification. The resulting models were robust to various kinds of perturbations: the growing CAs expressed regenerative capabilities to damage; the MNIST CAs were responsive to change in the underlying digits, triggering reclassification whenever necessary.</p>

<p>In this work, we explore further the robustness of these models by <i>training adversaries </i>whose goal is to reprogram the CAs into doing something other than what they were trained to do. We will explore two kinds of adversarial computations: injecting some adversarial CA into the collective pretrained models; and perturbing the global state of the cells with some adversarial operation.</p>

<p>For the first type of adversarial attacks we will train a new CA model such that, when placed in an environment with the original models described in the previous articles, is able to hijack the behavior of the collective CAs. [Biological comment]</p>

<p>The second type of adversarial attacks will interact with previously trained growing CA models without touching any cell's parameters. Instead, we will apply a global state perturbation to all alive cells. This can be seen as inhibiting or enhancing combinations of state values, in turn hijacking proper communications among cells and within the cell's own states. [Biological comments]</p>
<h1>Adversarial MNIST CAs</h1>
<p>As a brief recap, the Self-classifying MNIST digits task consisted in placing CAs on a plane forming the shape of an MNIST digit. The cells had to communicate among themselves in order to achieve a total agreement as to which digit they formed.</p>

<p>In this experiment, <strong>the goal is to create an adversarial CA that can hijack the global cells' classifications to always be an 8</strong>. We take the CA model trained on the previous article and freeze its parameters. We then train a new set of CAs whose model is identical to the specs of the frozen model but is randomly initialized. The training regime is mostly identical to the one used for training the self-classifying MNIST digits CAs. There are three important differences:</p>
<ul><li>Regardless of what the actual digit is, we consider <i>the correct classification to always be an 8</i>.</li>
<li>For each batch and each pixel, the CAs are randomly chosen to be either the pretrained model or the new adversarial one. We used a 10% chance of placing an adversarial CA instead of the pretrained one.</li>
<li>We train only the adversarial CA parameters and keep the pretrained model frozen.</li></ul>

<p>The task is remarkably simple to optimize [show training loss&#x2F;accuracy timeline?]. Here we show a few examples of test instances.</p>

<p>While we trained the adversaries with a 10% distribution, we can observe that very often we need significantly fewer adversaries to steer the entire classification towards an 8. [Show either eval graphs and&#x2F;or videos.]</p>

<p>We created a demo playground where the reader can draw digits and place adversaries with surgical precision. We encourage the reader to play with the demo to get a sense on how easily innocent cells can get swayed towards the wrong outcomes. </p>
<h1>Adversarial Injections for Growing CAs</h1>
<p>One question we may ask is whether the same kind of adversarial attack that was successful for the MNIST CA would work for the Growing CA model too. The Growing CA models' goals are to be able to grow a complex image pattern from a small seed, and having its result being persistent over time and robust to significant perturbations. The drawing below exemplifies what just described.</p>
<p>[ Add drawing of: from lizard seed to pattern, to perturbation to regeneration]</p>

<p>In this article, we will focus on the lizard pattern. The new goal will be to have some adversarial CAs change the global configuration of all the CAs, including the previously trained and now frozen lizard CAs.</p>
<p>We showcase two new targets for the adversaries to generate: a red lizard, and a tailless lizard. </p>
<p>[show new targets]</p>
<p>These targets have very different properties: converting a lizard from green to red would show a global change in the behaviour of the resulting CAs, while having a severed tail is a more localized change.</p>

<p>[Show how this fails completely&#x2F;partially]</p>
<p>I will describe this in more detail once I finalize the videos of interest.</p>

<p>These negative results are very interesting: a model of CA extremely similar to the one seen in MNIST CA shows a much greater resistance to adversarial perturbation than those of its cousin. This empirical difference is further puzzling by the fact that both models, during training, are asynchronous and exposed to sizeable perturbations, with the goal of making them both robust to out-of-training configurations.</p>

<p>One notable difference between the two models is that the MNIST CAs have to change their opinion (digit classification) based on the information that they receive from their neighbors because at any time the underlying digit may change in shape even if in a specific position there would be no apparent change. For instance, imagine the case of a "1" turning into a "7": from the point of view of the cells in the lower part of the digit, there is no change, yet the total digit is a 7 now. This may make the MNIST CAs more susceptible to individuals' signals rather than what happens in Growing CAs, where the totality of cells is responsible for generating a given shape and there is never a moment where cells have to reconfigure themselves for regenerating something different than before.</p>

<p>Following this hypothesis, we suspect that more general-purpose Growing CAs that have observed different target patterns during training are more likely to be susceptible to adversarial attacks.</p>
<h1>Perturbing the states of Growing CAs</h1>
<p>While we have observed robustness to groups of adversaries, our Growing CAs could still be weak to more <i>global </i>attacks. In this experiment, we perturb the state of every alive cell at every step with the same trainable perturbation. [bad phrasing].</p>
<figure>
<img src='images/mutations_mosaic.jpeg' style='width: 450px'>
<figcaption>Mosaic of the desired mutations we want to apply.</figcaption>
</figure>
<p>Explain math</p>

<p>Show individual videos of success with all different pattern targets</p>
<figure>
    <div class="vc">
    <div class="vidoverlay"></div>
    <video playsinline muted width="640px" preload="auto">
      <source src="figures/mutations_mosaic_video.mp4#t=0.1" type="video/mp4">
Your browser does not support the video tag.
    </video>
    </div>
<figcaption style="">
Effect of applying the trained perturbations.</figcaption>
</figure>


<p>Show "tail direction".</p>
<figure>
    <div class="vc">
    <div class="vidoverlay"></div>
    <video playsinline muted width="640px" preload="auto">
      <source src="figures/tail_direction_mosaic.mp4#t=0.1" type="video/mp4">
Your browser does not support the video tag.
    </video>
    </div>
<figcaption style="">
Effect of following the direction of the tail perturbation.</figcaption>
</figure>

<p>Show multiple mutations and playground.</p>
<figure>
    <div class="vc">
    <div class="vidoverlay"></div>
    <video playsinline muted width="640px" preload="auto">
      <source src="figures/combination_of_mutations.mp4#t=0.1" type="video/mp4">
Your browser does not support the video tag.
    </video>
    </div>
<figcaption style="">
Effect of composing two trained perturbations.</figcaption>
</figure>

<figure>
    <div class="vc">
    <div class="vidoverlay"></div>
    <video playsinline muted width="640px" preload="auto">
      <source src="figures/perturbation_playground.mp4#t=0.1" type="video/mp4">
Your browser does not support the video tag.
    </video>
    </div>
<figcaption style="">
Demonstration of the playground.</figcaption>
</figure>
<h1>Related work</h1>
<p>Both Adversarial key related work, and biological related work.</p>
<h1>Discussion</h1>
<p>Closing notes.</p>

</d-article>
<d-appendix>
    <d-footnote-list></d-footnote-list>
    <d-citation-list></d-citation-list>
</d-appendix>